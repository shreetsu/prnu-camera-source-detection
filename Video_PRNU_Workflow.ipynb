{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc893212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adbb2f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported PRNU from local repo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add local PRNU repo to Python path\n",
    "prnu_repo_path = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\prnu-python\"\n",
    "if prnu_repo_path not in sys.path:\n",
    "    sys.path.append(prnu_repo_path)\n",
    "\n",
    "# Now import PRNU functions from the local repo\n",
    "from prnu import extract_multiple_aligned, crosscorr_2d\n",
    "from prnu.functions import noise_extract_compact, rgb2gray\n",
    "\n",
    "print(\"‚úÖ Successfully imported PRNU from local repo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c476f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'c:\\Users\\inamy\\Desktop\\minor project\\prnu-camera-source-detection\\prnu-python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found devices: ['iphone15', 'OnePlus Nord CE4', 'Samsung S21 FE', 'Samsung S23 5g']\n",
      "\n",
      "üìç Processing fingerprints for: iphone15\n",
      "  ‚Üí Extracting frames from: IMG_5445.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5446.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.26it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5448.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.59it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.80it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5449.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5450.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5452.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.36it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5453.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.00it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: IMG_5456.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.90it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fingerprint saved for iphone15: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\iphone15_video_fingerprint.npy, shape: (384, 512)\n",
      "\n",
      "üìç Processing fingerprints for: OnePlus Nord CE4\n",
      "  ‚Üí Extracting frames from: VID20251030112943.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.00it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030112954.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.08it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113117.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.37it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113151.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113219.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.02it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113315.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.15it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113406.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.13it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.37it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.13it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113428.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.15it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113546.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.29it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113641.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: VID20251030113846.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fingerprint saved for OnePlus Nord CE4: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\OnePlus Nord CE4_video_fingerprint.npy, shape: (384, 512)\n",
      "\n",
      "üìç Processing fingerprints for: Samsung S21 FE\n",
      "  ‚Üí Extracting frames from: 20251017_194843.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_195010.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:01<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_195454.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.68it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.39it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_195706.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_200315.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.88it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_200651.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.81it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_200928.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.63it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.80it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20251017_201833.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.16it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.29it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fingerprint saved for Samsung S21 FE: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\Samsung S21 FE_video_fingerprint.npy, shape: (384, 512)\n",
      "\n",
      "üìç Processing fingerprints for: Samsung S23 5g\n",
      "  ‚Üí Extracting frames from: 20250306_131548.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.26it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.87it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250402_174439.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250413_081525.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.88it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250413_085810.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250413_185327.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.28it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.00it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250530_101017.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.08it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.64it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250531_171308.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.12it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250612_173237.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.67it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250620_175107.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.90it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.97it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Extracting frames from: 20250709_204001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  7.81it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fingerprint saved for Samsung S23 5g: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\Samsung S23 5g_video_fingerprint.npy, shape: (384, 512)\n"
     ]
    }
   ],
   "source": [
    "import os, glob, gc\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from prnu import extract_multiple_aligned\n",
    "\n",
    "# -------------------\n",
    "# SETTINGS\n",
    "# -------------------\n",
    "\n",
    "data_directory = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "fingerprint_directory = os.path.join(os.path.dirname(data_directory), 'fingerprints')\n",
    "os.makedirs(fingerprint_directory, exist_ok=True)\n",
    "\n",
    "TARGET_WIDTH = 512\n",
    "TARGET_HEIGHT = 384\n",
    "FRAMES_PER_VIDEO = 60       # Enough for PRNU\n",
    "BATCH_SIZE = 15             # Process only 15 frames at a time\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# HELPERS\n",
    "# -------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_width, target_height):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_width, target_height), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_width, target_height))\n",
    "    new_img.paste(img, ((target_width - img.width) // 2, (target_height - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def extract_frames_from_video(video_path, frames_per_video, TARGET_WIDTH, TARGET_HEIGHT):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ö†Ô∏è Could not open video file: {video_path}\")\n",
    "        return frames\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        return frames\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "            frames.append(img)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# -------------------\n",
    "# MAIN PROCESS\n",
    "# -------------------\n",
    "\n",
    "device_folders = [f for f in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, f))]\n",
    "print(f\"Found devices: {device_folders}\")\n",
    "\n",
    "for device in device_folders:\n",
    "    print(f\"\\nüìç Processing fingerprints for: {device}\")\n",
    "\n",
    "    video_dir = os.path.join(data_directory, device, 'videos', 'fingerprint_set')\n",
    "    video_paths = glob.glob(os.path.join(video_dir, '*.mp4')) + \\\n",
    "                  glob.glob(os.path.join(video_dir, '*.mov')) + \\\n",
    "                  glob.glob(os.path.join(video_dir, '*.avi'))\n",
    "\n",
    "    if not video_paths:\n",
    "        print(f\"‚ö†Ô∏è No video files found for {device}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fingerprint = None\n",
    "\n",
    "    for path in video_paths:\n",
    "        print(f\"  ‚Üí Extracting frames from: {os.path.basename(path)}\")\n",
    "        frames = extract_frames_from_video(path, FRAMES_PER_VIDEO, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "        if not frames:\n",
    "            print(f\"  ‚ö†Ô∏è No frames extracted from {path}\")\n",
    "            continue\n",
    "\n",
    "        # Process in batches to avoid memory spike\n",
    "        for i in range(0, len(frames), BATCH_SIZE):\n",
    "            batch = frames[i:i+BATCH_SIZE]\n",
    "\n",
    "            batch_uint8 = np.array(batch, dtype=np.uint8)\n",
    "\n",
    "            if fingerprint is None:\n",
    "                fingerprint = extract_multiple_aligned(batch_uint8, processes=0)\n",
    "            else:\n",
    "                fp_part = extract_multiple_aligned(batch_uint8, processes=0)\n",
    "                fingerprint = (fingerprint + fp_part) / 2\n",
    "\n",
    "            del batch_uint8\n",
    "            gc.collect()\n",
    "\n",
    "        del frames\n",
    "        gc.collect()\n",
    "\n",
    "    if fingerprint is None:\n",
    "        print(f\"‚ö†Ô∏è No fingerprint generated for {device}\")\n",
    "        continue\n",
    "\n",
    "    save_path = os.path.join(fingerprint_directory, f\"{device}_video_fingerprint.npy\")\n",
    "    np.save(save_path, fingerprint)\n",
    "    print(f\"‚úÖ Fingerprint saved for {device}: {save_path}, shape: {fingerprint.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb26d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM3D not available: falling back to OpenCV Non-local Means denoiser.\n",
      "\n",
      "=== QUERY SET EVALUATION (MAX ACCURACY HYBRID) ===\n",
      "\n",
      "\n",
      "üìç Device: iphone15  (query videos: 3)\n",
      "  ‚Üí Evaluating: IMG_5454.mp4\n",
      "     predicted: iphone15   agg_score: 71.2470\n",
      "  ‚Üí Evaluating: IMG_5455.mp4\n",
      "     predicted: iphone15   agg_score: 108.5406\n",
      "  ‚Üí Evaluating: IMG_5456 copy.mp4\n",
      "     predicted: iphone15   agg_score: 242.2021\n",
      "\n",
      "  ‚úÖ Query results for iphone15: 3/3 matched (100.0%)\n",
      "     ‚úì matched: IMG_5454.mp4, IMG_5455.mp4, IMG_5456 copy.mp4\n",
      "\n",
      "üìç Device: OnePlus Nord CE4  (query videos: 4)\n",
      "  ‚Üí Evaluating: VID20251030112624.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 69.9761\n",
      "  ‚Üí Evaluating: VID20251030112641.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 72.2863\n",
      "  ‚Üí Evaluating: VID20251030112807.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 96.7378\n",
      "  ‚Üí Evaluating: VID20251030112925.mp4\n",
      "     predicted: iphone15   agg_score: 81.5727\n",
      "\n",
      "  ‚úÖ Query results for OnePlus Nord CE4: 0/4 matched (0.0%)\n",
      "     ‚úó not matched: VID20251030112624.mp4, VID20251030112641.mp4, VID20251030112807.mp4, VID20251030112925.mp4\n",
      "\n",
      "üìç Device: Samsung S21 FE  (query videos: 2)\n",
      "  ‚Üí Evaluating: 20251017_194729.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 64.5059\n",
      "  ‚Üí Evaluating: 20251017_202243.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 74.0691\n",
      "\n",
      "  ‚úÖ Query results for Samsung S21 FE: 2/2 matched (100.0%)\n",
      "     ‚úì matched: 20251017_194729.mp4, 20251017_202243.mp4\n",
      "\n",
      "üìç Device: Samsung S23 5g  (query videos: 4)\n",
      "  ‚Üí Evaluating: 20250712_120212.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 63.4093\n",
      "  ‚Üí Evaluating: 20250914_130351.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 87.8335\n",
      "  ‚Üí Evaluating: 20250927_205316.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 91.2715\n",
      "  ‚Üí Evaluating: 20250930_173755.mp4\n",
      "     predicted: Samsung S21 FE   agg_score: 75.9880\n",
      "\n",
      "  ‚úÖ Query results for Samsung S23 5g: 0/4 matched (0.0%)\n",
      "     ‚úó not matched: 20250712_120212.mp4, 20250914_130351.mp4, 20250927_205316.mp4, 20250930_173755.mp4\n",
      "\n",
      "=== OVERALL SUMMARY ===\n",
      "Total matched: 5 / 13  -> Accuracy: 38.46%\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# MAX-ACCURACY HYBRID EVALUATOR\n",
    "# Run this cell after you've defined extract_frames_from_video(...) above.\n",
    "# ---------------------------\n",
    "\n",
    "import os, glob, math, gc\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from scipy import signal\n",
    "\n",
    "# Settings (tweak if needed)\n",
    "DATA_ROOT = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "FINGERPRINT_DIR = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\"\n",
    "\n",
    "FRAMES_PER_VIDEO = 60     # more frames -> stronger PRNU evidence\n",
    "DROP_BOTTOM_PERCENT = 30  # drop bottom 30% by quality\n",
    "BATCH_SIZE = 15           # used only if we later process in batches (not strictly required here)\n",
    "\n",
    "# Try BM3D for best denoising if installed; else fallback to OpenCV fastNlMeans\n",
    "try:\n",
    "    from bm3d import bm3d_rgb, bm3d\n",
    "    BM3D_AVAILABLE = True\n",
    "    print(\"BM3D available: using BM3D denoiser for best quality.\")\n",
    "except Exception:\n",
    "    BM3D_AVAILABLE = False\n",
    "    print(\"BM3D not available: falling back to OpenCV Non-local Means denoiser.\")\n",
    "\n",
    "# -------------------------\n",
    "# Utility functions\n",
    "# -------------------------\n",
    "def compute_sharpness(gray: np.ndarray) -> float:\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    return float(lap.var())\n",
    "\n",
    "def compute_texture_strength(gray: np.ndarray, ksize: int = 7) -> float:\n",
    "    img = gray.astype(np.float32)\n",
    "    blurred = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "    mean = cv2.boxFilter(blurred, ddepth=-1, ksize=(ksize, ksize))\n",
    "    mean_sq = cv2.boxFilter(blurred * blurred, ddepth=-1, ksize=(ksize, ksize))\n",
    "    local_var = mean_sq - (mean * mean)\n",
    "    return float(np.median(local_var))\n",
    "\n",
    "def standardize_scores(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if arr.size == 0:\n",
    "        return arr\n",
    "    mn = arr.min()\n",
    "    mx = arr.max()\n",
    "    if mx <= mn:\n",
    "        return np.ones_like(arr)\n",
    "    return (arr - mn) / (mx - mn)\n",
    "\n",
    "# Denoise using best available method\n",
    "def denoise_frame_rgb(frame_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input: RGB uint8 image (H, W, 3)\n",
    "    Output: denoised RGB as float32\n",
    "    \"\"\"\n",
    "    if BM3D_AVAILABLE:\n",
    "        # bm3d expects float in 0..1 or 0..255 depending on implementation; here we normalize to 0..1\n",
    "        im_f = frame_rgb.astype(np.float32) / 255.0\n",
    "        try:\n",
    "            den = bm3d_rgb(im_f, sigma_psd=10/255.0)  # heuristic sigma; BM3D sigma tuning may be needed\n",
    "            den = np.clip(den, 0.0, 1.0)\n",
    "            return (den * 255.0).astype(np.float32)\n",
    "        except Exception:\n",
    "            # fallback if bm3d_rgb signature differs\n",
    "            den = bm3d(frame_rgb.astype(np.float32) / 255.0)\n",
    "            return (np.clip(den, 0.0, 1.0) * 255.0).astype(np.float32)\n",
    "    else:\n",
    "        # OpenCV colored denoising is decent: convert to BGR since opencv function expects that\n",
    "        bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        # h parameters tuned for strong denoising but preserving PRNU as much as possible\n",
    "        den_bgr = cv2.fastNlMeansDenoisingColored(bgr, None, h=10, hColor=10, templateWindowSize=7, searchWindowSize=21)\n",
    "        den_rgb = cv2.cvtColor(den_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return den_rgb.astype(np.float32)\n",
    "\n",
    "def extract_noise_residual(frame_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute noise residual = frame - denoised_frame, return grayscale residual normalized (zero-mean, unit-std).\n",
    "    Input frame_rgb: uint8 RGB\n",
    "    Output: float32 2D array\n",
    "    \"\"\"\n",
    "    den = denoise_frame_rgb(frame_rgb)\n",
    "    # compute residual in float\n",
    "    residual = frame_rgb.astype(np.float32) - den.astype(np.float32)\n",
    "    # convert to grayscale residual (weighted)\n",
    "    if residual.ndim == 3:\n",
    "        res_gray = 0.2989 * residual[...,0] + 0.5870 * residual[...,1] + 0.1140 * residual[...,2]\n",
    "    else:\n",
    "        res_gray = residual.astype(np.float32)\n",
    "    # normalize to zero mean and unit var\n",
    "    mu = np.mean(res_gray)\n",
    "    sigma = np.std(res_gray) + 1e-10\n",
    "    res_norm = (res_gray - mu) / sigma\n",
    "    return res_norm.astype(np.float32)\n",
    "\n",
    "# FFT-based cross-correlation (returns full correlation map)\n",
    "def crosscorr_2d_fft(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute normalized cross-correlation map using FFT convolution.\n",
    "    Both a and b are same-shape 2D arrays. We compute cross-correlation and normalize.\n",
    "    \"\"\"\n",
    "    # ensure float32\n",
    "    a = a.astype(np.float32)\n",
    "    b = b.astype(np.float32)\n",
    "    # zero-mean\n",
    "    a = a - a.mean()\n",
    "    b = b - b.mean()\n",
    "    # flip b for cross-correlation equivalence with convolution\n",
    "    b_flip = np.flipud(np.fliplr(b))\n",
    "    conv = signal.fftconvolve(a, b_flip, mode='same')\n",
    "    # normalisation: divide by sqrt(Ea * Eb) where Ea are local energy maps (approx)\n",
    "    # We'll approximate denominator with global energies for speed (consistent across comparisons)\n",
    "    denom = np.sqrt((a**2).sum() * (b**2).sum()) + 1e-10\n",
    "    return conv / denom\n",
    "\n",
    "def compute_pce_from_corrmap(corr: np.ndarray, ignore_radius: int = 11) -> float:\n",
    "    \"\"\"\n",
    "    Compute Peak-to-Correlation Energy (PCE) from correlation map.\n",
    "    PCE = (peak^2) / (variance of correlation excluding small neighborhood around peak)\n",
    "    \"\"\"\n",
    "    if corr.size == 0:\n",
    "        return float('-inf')\n",
    "    peak_idx = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "    peak_val = corr[peak_idx]\n",
    "    # mask out small neighborhood\n",
    "    h, w = corr.shape\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    mask = np.ones_like(corr, dtype=bool)\n",
    "    y0, x0 = peak_idx\n",
    "    rr = (Y - y0)**2 + (X - x0)**2\n",
    "    mask[rr <= (ignore_radius**2)] = False\n",
    "    outside = corr[mask]\n",
    "    if outside.size <= 1:\n",
    "        return float('-inf')\n",
    "    var_out = outside.var()\n",
    "    if var_out <= 1e-12:\n",
    "        return float('inf') if peak_val > 0 else float('-inf')\n",
    "    pce = (peak_val**2) / var_out\n",
    "    return float(pce)\n",
    "\n",
    "# rotation + flip scanning for best PCE\n",
    "def best_pce_between(residual_frame: np.ndarray, fp_map: np.ndarray) -> float:\n",
    "    best = float('-inf')\n",
    "    # ensure same shape: if fingerprint differs, resize fingerprint to frame size\n",
    "    if fp_map.shape != residual_frame.shape:\n",
    "        fp_resized = cv2.resize(fp_map.astype(np.float32), (residual_frame.shape[1], residual_frame.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        fp_resized = fp_map.astype(np.float32)\n",
    "    # normalize fingerprint similarly\n",
    "    fp_resized = (fp_resized - fp_resized.mean()) / (fp_resized.std() + 1e-10)\n",
    "    # try 4 rotations and flips\n",
    "    for k in range(4):\n",
    "        rot = np.rot90(residual_frame, k)\n",
    "        for flip in (False, True):\n",
    "            test = np.fliplr(rot) if flip else rot\n",
    "            corr = crosscorr_2d_fft(test, fp_resized)\n",
    "            pce = compute_pce_from_corrmap(corr, ignore_radius=11)\n",
    "            if pce > best:\n",
    "                best = pce\n",
    "    return best\n",
    "\n",
    "# Adaptive aggregation across frames\n",
    "def aggregate_video_scores(frame_pces: List[float], quality_vals: List[float], drop_bottom_pct: float = DROP_BOTTOM_PERCENT) -> Tuple[float, List[int]]:\n",
    "    if len(frame_pces) == 0:\n",
    "        return float('-inf'), []\n",
    "    frame_pces = np.asarray(frame_pces, dtype=np.float32)\n",
    "    quality_vals = np.asarray(quality_vals, dtype=np.float32)\n",
    "    cutoff = np.percentile(quality_vals, drop_bottom_pct)\n",
    "    keep_mask = quality_vals > cutoff\n",
    "    if not np.any(keep_mask):\n",
    "        keep_mask[int(np.argmax(quality_vals))] = True\n",
    "    kept_idx = np.where(keep_mask)[0].tolist()\n",
    "    kept_pces = frame_pces[keep_mask]\n",
    "    kept_quals = quality_vals[keep_mask]\n",
    "    q_norm = standardize_scores(kept_quals)\n",
    "    if q_norm.sum() <= 0:\n",
    "        weights = np.ones_like(q_norm) / len(q_norm)\n",
    "    else:\n",
    "        weights = q_norm / q_norm.sum()\n",
    "    agg = float(np.sum(kept_pces * weights))\n",
    "    return agg, kept_idx\n",
    "\n",
    "# -------------------------\n",
    "# Matching per video\n",
    "# -------------------------\n",
    "def match_video_to_fingerprints(video_path: str, fingerprints: Dict[str, np.ndarray],\n",
    "                                frames_per_video: int = FRAMES_PER_VIDEO,\n",
    "                                target_w: int = None, target_h: int = None) -> Tuple[Optional[str], float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Returns (predicted_device, aggregated_score, per_device_score_map)\n",
    "    \"\"\"\n",
    "    # Use your earlier extract_frames_from_video function ‚Äî ensure it's defined in the notebook\n",
    "    if target_w is None or target_h is None:\n",
    "        frames = extract_frames_from_video(video_path, frames_per_video, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "    else:\n",
    "        frames = extract_frames_from_video(video_path, frames_per_video, target_w, target_h)\n",
    "    if not frames:\n",
    "        return None, float('-inf'), {}\n",
    "\n",
    "    frame_pces_per_device = {dev: [] for dev in fingerprints.keys()}\n",
    "    quality_vals = []\n",
    "\n",
    "    # Process frames sequentially (memory safe)\n",
    "    for frame in frames:\n",
    "        # ensure uint8 RGB\n",
    "        frame_uint8 = frame.astype(np.uint8)\n",
    "        # compute quality from original frame\n",
    "        gray = cv2.cvtColor(frame_uint8, cv2.COLOR_RGB2GRAY)\n",
    "        sharp = compute_sharpness(gray)\n",
    "        text = compute_texture_strength(gray)\n",
    "        quality_vals.append(0.5 * sharp + 0.5 * text)\n",
    "\n",
    "        # compute residual\n",
    "        res = extract_noise_residual(frame_uint8)  # float32 normalized\n",
    "\n",
    "        # for each device fingerprint compute pce\n",
    "        for dev, fp in fingerprints.items():\n",
    "            # prepare fingerprint grayscale map\n",
    "            if fp.ndim == 3:\n",
    "                fp_gray = 0.2989 * fp[...,0] + 0.5870 * fp[...,1] + 0.1140 * fp[...,2]\n",
    "            else:\n",
    "                fp_gray = fp.astype(np.float32)\n",
    "            pce = best_pce_between(res, fp_gray)\n",
    "            frame_pces_per_device[dev].append(pce)\n",
    "\n",
    "    # Aggregate per device\n",
    "    agg_scores = {}\n",
    "    for dev, pces in frame_pces_per_device.items():\n",
    "        agg, kept_idx = aggregate_video_scores(pces, quality_vals, drop_bottom_pct=DROP_BOTTOM_PERCENT)\n",
    "        agg_scores[dev] = agg\n",
    "\n",
    "    # choose best device\n",
    "    best_dev = max(agg_scores.items(), key=lambda x: x[1])[0]\n",
    "    best_score = agg_scores[best_dev]\n",
    "    return best_dev, best_score, agg_scores\n",
    "\n",
    "# -------------------------\n",
    "# Main evaluation loop across devices' query_set\n",
    "# -------------------------\n",
    "def evaluate_all_query_sets(data_root: str = DATA_ROOT, fingerprint_dir: str = FINGERPRINT_DIR):\n",
    "    # Load fingerprints from fingerprint_dir\n",
    "    fingerprints = {}\n",
    "    for f in os.listdir(fingerprint_dir):\n",
    "        if f.endswith('_video_fingerprint.npy'):\n",
    "            dev = f.replace('_video_fingerprint.npy', '')\n",
    "            fp = np.load(os.path.join(fingerprint_dir, f))\n",
    "            fingerprints[dev] = fp\n",
    "    if not fingerprints:\n",
    "        print(\"No fingerprints found. Generate fingerprints first.\")\n",
    "        return\n",
    "\n",
    "    devices = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
    "    overall_total = 0\n",
    "    overall_correct = 0\n",
    "\n",
    "    print(\"\\n=== QUERY SET EVALUATION (MAX ACCURACY HYBRID) ===\\n\")\n",
    "    for dev in devices:\n",
    "        qdir = os.path.join(data_root, dev, 'videos', 'query_set')\n",
    "        if not os.path.isdir(qdir):\n",
    "            print(f\"No query_set for device {dev}, skipping.\")\n",
    "            continue\n",
    "        video_paths = sorted(glob.glob(os.path.join(qdir, '*.mp4')) + glob.glob(os.path.join(qdir, '*.mov')) + glob.glob(os.path.join(qdir, '*.avi')))\n",
    "        if not video_paths:\n",
    "            print(f\"No query videos found for {dev}.\")\n",
    "            continue\n",
    "\n",
    "        correct = 0\n",
    "        matched_list, notmatched_list = [], []\n",
    "        print(f\"\\nüìç Device: {dev}  (query videos: {len(video_paths)})\")\n",
    "\n",
    "        for v in video_paths:\n",
    "            print(f\"  ‚Üí Evaluating: {os.path.basename(v)}\")\n",
    "            pred, score, per_dev = match_video_to_fingerprints(v, fingerprints)\n",
    "            print(f\"     predicted: {pred}   agg_score: {score:.4f}\")\n",
    "            if pred == dev:\n",
    "                correct += 1\n",
    "                matched_list.append(os.path.basename(v))\n",
    "            else:\n",
    "                notmatched_list.append(os.path.basename(v))\n",
    "\n",
    "        overall_total += len(video_paths)\n",
    "        overall_correct += correct\n",
    "\n",
    "        pct = (correct / len(video_paths) * 100) if video_paths else 0.0\n",
    "        print(f\"\\n  ‚úÖ Query results for {dev}: {correct}/{len(video_paths)} matched ({pct:.1f}%)\")\n",
    "        if matched_list:\n",
    "            print(f\"     ‚úì matched: {', '.join(matched_list)}\")\n",
    "        if notmatched_list:\n",
    "            print(f\"     ‚úó not matched: {', '.join(notmatched_list)}\")\n",
    "\n",
    "    overall_acc = (overall_correct / overall_total * 100) if overall_total > 0 else 0.0\n",
    "    print(\"\\n=== OVERALL SUMMARY ===\")\n",
    "    print(f\"Total matched: {overall_correct} / {overall_total}  -> Accuracy: {overall_acc:.2f}%\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_all_query_sets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1399919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loaded fingerprint for iphone15, shape: (384, 512)\n",
      "[+] Loaded fingerprint for OnePlus Nord CE4, shape: (384, 512)\n",
      "[+] Loaded fingerprint for Samsung S21 FE, shape: (384, 512)\n",
      "[+] Loaded fingerprint for Samsung S23 5g, shape: (384, 512)\n",
      "\n",
      "--- Checking videos for iphone15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_5454.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.73it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.70it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.15it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_5455.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.89it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_5456 copy.mp4 ‚Üí Predicted: iphone15\n",
      "\n",
      "--- Checking videos for OnePlus Nord CE4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.84it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.97it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID20251030112624.mp4 ‚Üí Predicted: Samsung S21 FE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.44it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID20251030112641.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.84it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID20251030112807.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.45it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID20251030112925.mp4 ‚Üí Predicted: OnePlus Nord CE4\n",
      "\n",
      "--- Checking videos for Samsung S21 FE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.73it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.91it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20251017_194729.mp4 ‚Üí Predicted: Samsung S23 5g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.87it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.88it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20251017_202243.mp4 ‚Üí Predicted: Samsung S21 FE\n",
      "\n",
      "--- Checking videos for Samsung S23 5g ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.31it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250712_120212.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.83it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.68it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250914_130351.mp4 ‚Üí Predicted: iphone15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  7.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250927_205316.mp4 ‚Üí Predicted: Samsung S21 FE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250930_173755.mp4 ‚Üí Predicted: iphone15\n",
      "\n",
      "======== FINAL RESULTS ========\n",
      "iphone15 has 3 videos: correct categorizations = 3/3\n",
      "OnePlus Nord CE4 has 4 videos: correct categorizations = 1/4\n",
      "Samsung S21 FE has 2 videos: correct categorizations = 1/2\n",
      "Samsung S23 5g has 4 videos: correct categorizations = 0/4\n",
      "\n",
      "Overall Accuracy: 5/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from prnu import extract_multiple_aligned\n",
    "from PIL import Image\n",
    "\n",
    "# -------- CONFIG --------\n",
    "DEVICES = ['iphone15', 'OnePlus Nord CE4', 'Samsung S21 FE', 'Samsung S23 5g']\n",
    "FINGERPRINT_DIR = r\"fingerprints\"\n",
    "BASE_QUERY_PATH = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "\n",
    "TARGET_WIDTH = 512\n",
    "TARGET_HEIGHT = 384\n",
    "FRAMES_PER_VIDEO = 50   # can reduce for speed\n",
    "BATCH_SIZE = 10\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def resize_with_padding(img_np, target_width, target_height):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_width, target_height), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_width, target_height))\n",
    "    new_img.paste(img, ((target_width - img.width) // 2, (target_height - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def extract_prnu_query(video_path):\n",
    "    \"\"\"Extract PRNU using SAME method as fingerprint generation.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, FRAMES_PER_VIDEO, dtype=int)\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "        frames.append(img)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return None\n",
    "\n",
    "    # Compute PRNU using extract_multiple_aligned to match fingerprint method\n",
    "    prnu = None\n",
    "    for i in range(0, len(frames), BATCH_SIZE):\n",
    "        batch = np.array(frames[i:i+BATCH_SIZE], dtype=np.uint8)\n",
    "        prnu_part = extract_multiple_aligned(batch, processes=0)\n",
    "\n",
    "        prnu = prnu_part if prnu is None else (prnu + prnu_part) / 2\n",
    "\n",
    "    return prnu\n",
    "\n",
    "\n",
    "def normalized_cross_correlation(a, b):\n",
    "    a = (a - np.mean(a)) / (np.std(a) + 1e-8)\n",
    "    b = (b - np.mean(b)) / (np.std(b) + 1e-8)\n",
    "    return np.mean(a * b)\n",
    "\n",
    "\n",
    "# Load stored fingerprints\n",
    "fingerprints = {}\n",
    "for device in DEVICES:\n",
    "    fp_path = os.path.join(FINGERPRINT_DIR, f\"{device}_video_fingerprint.npy\")\n",
    "    if os.path.exists(fp_path):\n",
    "        fingerprints[device] = np.load(fp_path)\n",
    "        print(f\"[+] Loaded fingerprint for {device}, shape: {fingerprints[device].shape}\")\n",
    "    else:\n",
    "        print(f\"[!] Missing fingerprint for {device}\")\n",
    "\n",
    "\n",
    "results = {d: {\"correct\": 0, \"total\": 0} for d in DEVICES}\n",
    "\n",
    "\n",
    "# ---- MATCHING ----\n",
    "for device in DEVICES:\n",
    "    query_folder = os.path.join(BASE_QUERY_PATH, device, \"videos\", \"query_set\")\n",
    "    query_videos = glob(os.path.join(query_folder, \"*.mp4\"))\n",
    "\n",
    "    print(f\"\\n--- Checking videos for {device} ---\")\n",
    "    for video in query_videos:\n",
    "        query_prnu = extract_prnu_query(video)\n",
    "\n",
    "        if query_prnu is None:\n",
    "            print(f\"‚ùå Could not extract PRNU for {video}\")\n",
    "            continue\n",
    "\n",
    "        scores = {dev_name: normalized_cross_correlation(query_prnu, fp)\n",
    "                  for dev_name, fp in fingerprints.items()}\n",
    "\n",
    "        predicted_device = max(scores, key=scores.get)\n",
    "\n",
    "        results[device][\"total\"] += 1\n",
    "        if predicted_device == device:\n",
    "            results[device][\"correct\"] += 1\n",
    "\n",
    "        print(f\"{os.path.basename(video)} ‚Üí Predicted: {predicted_device}\")\n",
    "\n",
    "\n",
    "# ---- SUMMARY ----\n",
    "print(\"\\n======== FINAL RESULTS ========\")\n",
    "total_correct = 0\n",
    "total_videos = 0\n",
    "\n",
    "for device, data in results.items():\n",
    "    correct = data[\"correct\"]\n",
    "    total = data[\"total\"]\n",
    "    total_correct += correct\n",
    "    total_videos += total\n",
    "    print(f\"{device} has {total} videos: correct categorizations = {correct}/{total}\")\n",
    "\n",
    "print(\"\\nOverall Accuracy:\", f\"{total_correct}/{total_videos}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8603f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_device_from_video(video_path: str,\n",
    "                               fingerprint_dir: str = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\") -> None:\n",
    "    \"\"\"\n",
    "    Identify which device a single video most likely came from.\n",
    "    Prints the result and returns (predicted_device, score, per_device_scores)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"‚ùå Video not found: {video_path}\")\n",
    "        return None, None, {}\n",
    "\n",
    "    # Load fingerprints\n",
    "    fingerprints = {}\n",
    "    for f in os.listdir(fingerprint_dir):\n",
    "        if f.endswith('_video_fingerprint.npy'):\n",
    "            dev = f.replace('_video_fingerprint.npy', '')\n",
    "            fp = np.load(os.path.join(fingerprint_dir, f))\n",
    "            fingerprints[dev] = fp\n",
    "\n",
    "    if not fingerprints:\n",
    "        print(\"‚ùå No fingerprints found. Generate them first.\")\n",
    "        return None, None, {}\n",
    "\n",
    "    print(f\"\\nüîç Identifying device for video: {os.path.basename(video_path)}\")\n",
    "\n",
    "    pred, score, per_device_scores = match_video_to_fingerprints(video_path, fingerprints)\n",
    "\n",
    "    print(\"\\n===== RESULT =====\")\n",
    "    print(f\"üìå Predicted Device: **{pred}**\")\n",
    "    print(f\"üìà Confidence Score: {score:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Scores for All Devices (Higher = Better) ---\")\n",
    "    for dev, sc in sorted(per_device_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{dev:20} : {sc:.4f}\")\n",
    "\n",
    "    print(\"==================\\n\")\n",
    "\n",
    "    return pred, score, per_device_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d966ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Cross-Correlation Matching (Including Rotation + Flipping) ---\n",
      "  - Max Correlation with iphone15 (over 5 frames): 7258.4644\n",
      "  - Max Correlation with OnePlus Nord CE4 (over 5 frames): 7681.9429\n",
      "  - Max Correlation with Samsung S21 FE (over 5 frames): 6285.2227\n",
      "  - Max Correlation with Samsung S23 5g (over 5 frames): 7248.3530\n",
      "\n",
      "--- Final Results ---\n",
      "üöÄ The best match for the test video is: **OnePlus Nord CE4** with a score of 7681.9429\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: MATCHING WITH ROTATION HANDLING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize(img):\n",
    "    \"\"\"Zero-mean, unit-variance normalization.\"\"\"\n",
    "    return (img - np.mean(img)) / (np.std(img) + 1e-8)\n",
    "\n",
    "best_match_device = None\n",
    "highest_correlation = -1.0\n",
    "\n",
    "print(\"\\n--- Starting Cross-Correlation Matching (Including Rotation + Flipping) ---\")\n",
    "\n",
    "for device, fingerprint in fingerprints.items():\n",
    "    \n",
    "    # Convert fingerprint to grayscale if needed and normalize\n",
    "    fp_gray = rgb2gray(fingerprint) if fingerprint.ndim == 3 else fingerprint\n",
    "    fp_gray = normalize(fp_gray)\n",
    "\n",
    "    device_scores = []\n",
    "    \n",
    "    for frame_idx, query_noise_gray in enumerate(query_noise_residuals):\n",
    "        query_noise_gray = normalize(query_noise_gray)\n",
    "        \n",
    "        # Test 4 rotations and horizontal flipping\n",
    "        frame_scores = []\n",
    "        for k in range(4):  # 0, 90, 180, 270 degrees\n",
    "            rotated_noise = np.rot90(query_noise_gray, k)\n",
    "            \n",
    "            for flip in [False, True]:\n",
    "                noise_test = np.fliplr(rotated_noise) if flip else rotated_noise\n",
    "                correlation_map = crosscorr_2d(noise_test, fp_gray)\n",
    "                frame_scores.append(float(np.max(correlation_map)))\n",
    "        \n",
    "        device_scores.append(np.max(frame_scores))\n",
    "\n",
    "    max_device_correlation = np.max(device_scores)\n",
    "    print(f\"  - Max Correlation with {device} (over {len(device_scores)} frames): {max_device_correlation:.4f}\")\n",
    "\n",
    "    if max_device_correlation > highest_correlation:\n",
    "        highest_correlation = max_device_correlation\n",
    "        best_match_device = device\n",
    "\n",
    "print(\"\\n--- Final Results ---\")\n",
    "if best_match_device is not None:\n",
    "    print(f\"üöÄ The best match for the test video is: **{best_match_device}** with a score of {highest_correlation:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No reliable match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73733058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, gc\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from prnu import extract_multiple_aligned\n",
    "\n",
    "# -------------------\n",
    "# SETTINGS\n",
    "# -------------------\n",
    "\n",
    "data_directory = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "fingerprint_directory = os.path.join(os.path.dirname(data_directory), 'fingerprints')\n",
    "os.makedirs(fingerprint_directory, exist_ok=True)\n",
    "\n",
    "TARGET_WIDTH = 512\n",
    "TARGET_HEIGHT = 384\n",
    "FRAMES_PER_VIDEO = 60\n",
    "BATCH_SIZE = 15\n",
    "MAX_VIDEOS = 8    # Use EXACTLY 8 videos per device\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# HELPERS\n",
    "# -------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_width, target_height):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_width, target_height), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_width, target_height))\n",
    "    new_img.paste(img, ((target_width - img.width) // 2, (target_height - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def extract_frames_g_channel(video_path, frames_per_video):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            resized = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "            # Keep **only green channel**\n",
    "            g_channel = resized[:, :, 1]\n",
    "            frames.append(g_channel)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# MAIN PROCESS\n",
    "# -------------------\n",
    "\n",
    "device_folders = [f for f in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, f))]\n",
    "print(f\"Found devices: {device_folders}\")\n",
    "\n",
    "for device in device_folders:\n",
    "    print(f\"\\nüìç Processing fingerprints for: {device}\")\n",
    "\n",
    "    video_dir = os.path.join(data_directory, device, 'videos', 'fingerprint_set')\n",
    "    video_paths = sorted(glob.glob(os.path.join(video_dir, '*.mp4')) +\n",
    "                         glob.glob(os.path.join(video_dir, '*.mov')) +\n",
    "                         glob.glob(os.path.join(video_dir, '*.avi')))\n",
    "\n",
    "    if len(video_paths) == 0:\n",
    "        print(f\"‚ö†Ô∏è No fingerprint videos found for {device}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Balance: Use only first 8 videos\n",
    "    video_paths = video_paths[:MAX_VIDEOS]\n",
    "    print(f\"Using {len(video_paths)} videos for fingerprint.\")\n",
    "\n",
    "    fp_sum = None\n",
    "    count = 0\n",
    "\n",
    "    for path in video_paths:\n",
    "        print(f\"  ‚Üí Extracting frames from: {os.path.basename(path)}\")\n",
    "        frames = extract_frames_g_channel(path, FRAMES_PER_VIDEO)\n",
    "\n",
    "        if not frames:\n",
    "            print(f\"  ‚ö†Ô∏è No frames extracted from {path}\")\n",
    "            continue\n",
    "\n",
    "        # Process in batches to avoid memory spike\n",
    "        for i in range(0, len(frames), BATCH_SIZE):\n",
    "            batch = np.array(frames[i:i+BATCH_SIZE], dtype=np.uint8)\n",
    "            batch = np.expand_dims(batch, axis=-1)  # shape (batch, H, W, 1)\n",
    "\n",
    "            prnu_part = extract_multiple_aligned(batch, processes=0)\n",
    "\n",
    "            if fp_sum is None:\n",
    "                fp_sum = prnu_part\n",
    "            else:\n",
    "                fp_sum += prnu_part\n",
    "\n",
    "            count += 1\n",
    "            del batch\n",
    "            gc.collect()\n",
    "\n",
    "        del frames\n",
    "        gc.collect()\n",
    "\n",
    "    if fp_sum is None:\n",
    "        print(f\"‚ö†Ô∏è No fingerprint generated for {device}\")\n",
    "        continue\n",
    "\n",
    "    fingerprint = fp_sum / count\n",
    "    save_path = os.path.join(fingerprint_directory, f\"{device}_video_fingerprint.npy\")\n",
    "    np.save(save_path, fingerprint)\n",
    "\n",
    "    print(f\"‚úÖ Saved fingerprint for {device}: {save_path}, shape: {fingerprint.shape}, averaged over {count} PRNU chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52b4bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bm3d\n",
      "  Downloading bm3d-4.0.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting bm4d>=4.2.5 (from bm3d)\n",
      "  Downloading bm4d-4.2.5-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bm4d>=4.2.5->bm3d) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.13.0 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bm4d>=4.2.5->bm3d) (1.15.2)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\khushi\\appdata\\roaming\\python\\python312\\site-packages (from bm4d>=4.2.5->bm3d) (1.9.0)\n",
      "Downloading bm3d-4.0.3-py3-none-any.whl (10 kB)\n",
      "Downloading bm4d-4.2.5-py3-none-any.whl (862 kB)\n",
      "   ---------------------------------------- 0.0/862.0 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/862.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 862.0/862.0 kB 3.0 MB/s  0:00:00\n",
      "Installing collected packages: bm4d, bm3d\n",
      "\n",
      "   ---------------------------------------- 0/2 [bm4d]\n",
      "   ---------------------------------------- 2/2 [bm3d]\n",
      "\n",
      "Successfully installed bm3d-4.0.3 bm4d-4.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.15.2)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (11.2.1)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.10.16-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 2.1 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.0/12.9 MB 1.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/12.9 MB 2.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.9 MB 2.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/12.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.0/12.9 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.8/12.9 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.9 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.7/12.9 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.0/12.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 3.9 MB/s  0:00:03\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2025.10.16-py3-none-any.whl (231 kB)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
      "\n",
      "   ---------------------------------------- 0/4 [tifffile]\n",
      "   -------------------- ------------------- 2/4 [imageio]\n",
      "   -------------------- ------------------- 2/4 [imageio]\n",
      "   -------------------- ------------------- 2/4 [imageio]\n",
      "   -------------------- ------------------- 2/4 [imageio]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ------------------------------ --------- 3/4 [scikit-image]\n",
      "   ---------------------------------------- 4/4 [scikit-image]\n",
      "\n",
      "Successfully installed imageio-2.37.0 lazy-loader-0.4 scikit-image-0.25.2 tifffile-2025.10.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bm3d\n",
    "!pip install scikit-image opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55bdbdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bm3d in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.3)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\khushi\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: bm4d>=4.2.5 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bm3d) (4.2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\khushi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\khushi\\appdata\\roaming\\python\\python312\\site-packages (from bm4d>=4.2.5->bm3d) (1.9.0)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/38.9 MB 1.3 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 1.0/38.9 MB 1.4 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 1.6/38.9 MB 1.6 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.8/38.9 MB 1.6 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 2.6/38.9 MB 1.9 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 3.1/38.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 3.9/38.9 MB 2.2 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 4.5/38.9 MB 2.3 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 5.2/38.9 MB 2.4 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 6.3/38.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 7.3/38.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.4/38.9 MB 3.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 9.2/38.9 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 10.2/38.9 MB 3.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 11.3/38.9 MB 3.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 12.6/38.9 MB 3.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 13.6/38.9 MB 3.5 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 14.9/38.9 MB 3.7 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 16.3/38.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 17.6/38.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.9/38.9 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.7/38.9 MB 4.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 21.0/38.9 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 22.3/38.9 MB 4.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.3/38.9 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.4/38.9 MB 4.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 25.4/38.9 MB 4.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.7/38.9 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 28.0/38.9 MB 4.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 29.1/38.9 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 30.1/38.9 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.9 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.9/38.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.0/38.9 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/38.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.9/38.9 MB 4.5 MB/s  0:00:08\n",
      "Installing collected packages: opencv-python-headless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Khushi\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Jupyter / VSCode cell\n",
    "!pip install bm3d opencv-python-headless numpy scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0ed3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fingerprint for: Samsung S23 5g\n",
      "[+] Saved fingerprint for Samsung S23 5g: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\Samsung S23 5g_video_fingerprint.npy shape=(768, 1024) (avg over 64 frames)\n",
      "[+] Fingerprint generated and saved at: C:\\Users\\Khushi\\prnu-camera-source-detection\\fingerprints\\Samsung S23 5g_video_fingerprint.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef main():\\n    devices = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\\n    if not devices:\\n        print(\"[!] No device folders found in DATA_DIR\")\\n        return\\n\\n    print(\"Devices:\", devices)\\n    print(\"\\n[Running sequential mode to avoid Windows multiprocessing hang]\\n\")\\n\\n    results = []\\n    for dev in devices:\\n        print(f\"\\nProcessing fingerprint for: {dev}\")\\n        result = compute_device_fingerprint(dev)\\n        results.append(result)\\n\\n    # summary\\n    print(\"\\n======== SUMMARY ========\")\\n    for dev, path in results:\\n        if path is None:\\n            print(f\"[!] Fingerprint failed for {dev}\")\\n        else:\\n            print(f\"[+] Fingerprint ready: {dev} -> {path}\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate_fingerprints_fast.py\n",
    "- Fast BM3D-based fingerprint generation (parallel per device)\n",
    "- Y-channel, BM3D mild, target size 1024x768\n",
    "- Uses up to 8 videos per device, 8 frames per video\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, gc\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from bm3d import bm3d\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# ------- CONFIG -------\n",
    "DATA_DIR = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "FINGERPRINT_DIR = os.path.join(os.path.dirname(DATA_DIR), \"fingerprints\")\n",
    "os.makedirs(FINGERPRINT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_WIDTH = 1024\n",
    "TARGET_HEIGHT = 768\n",
    "MAX_VIDEOS = 8\n",
    "FRAMES_PER_VIDEO = 8          # reduced for speed, still good quality\n",
    "BATCH_SIZE = 8\n",
    "BM3D_SIGMA = 2.5 / 255.0      # mild BM3D\n",
    "WORKERS = max(1, min(cpu_count() - 1, 6))  # cap workers to avoid oversubscribe\n",
    "# ----------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_w, target_h):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_w, target_h), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_w, target_h))\n",
    "    new_img.paste(img, ((target_w - img.width) // 2, (target_h - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "def extract_y_frames_from_video(video_path, frames_per_video):\n",
    "    frames_y = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return frames_y\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total == 0:\n",
    "        cap.release()\n",
    "        return frames_y\n",
    "    indices = np.linspace(0, total - 1, frames_per_video, dtype=int)\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "        ycc = cv2.cvtColor(resized, cv2.COLOR_RGB2YCrCb)\n",
    "        y = ycc[:, :, 0]\n",
    "        frames_y.append(y.astype(np.float32) / 255.0)  # normalize\n",
    "    cap.release()\n",
    "    return frames_y\n",
    "\n",
    "def process_video_frames_to_residuals(frames_y):\n",
    "    \"\"\"Denoise frames with BM3D and return residuals list.\"\"\"\n",
    "    residuals = []\n",
    "    for imgf in frames_y:\n",
    "        try:\n",
    "            den = bm3d(imgf, BM3D_SIGMA, stage_arg=bm3d.STAGE_ALL)\n",
    "        except Exception:\n",
    "            den = bm3d(imgf, BM3D_SIGMA)\n",
    "        resid = imgf - den\n",
    "        residuals.append(resid.astype(np.float32))\n",
    "    return residuals\n",
    "\n",
    "def compute_device_fingerprint(device_name):\n",
    "    \"\"\"Compute fingerprint for one device (used by Pool).\"\"\"\n",
    "    video_dir = os.path.join(DATA_DIR, device_name, \"videos\", \"fingerprint_set\")\n",
    "    video_paths = sorted(glob.glob(os.path.join(video_dir, \"*.mp4\")) +\n",
    "                         glob.glob(os.path.join(video_dir, \"*.mov\")) +\n",
    "                         glob.glob(os.path.join(video_dir, \"*.avi\")))\n",
    "    if len(video_paths) == 0:\n",
    "        print(f\"[!] No fingerprint videos for {device_name} in {video_dir}\")\n",
    "        return device_name, None\n",
    "\n",
    "    use_paths = video_paths[:MAX_VIDEOS]\n",
    "    fp_sum = None\n",
    "    count = 0\n",
    "\n",
    "    # iterate videos, process frames -> residuals\n",
    "    for vp in use_paths:\n",
    "        frames_y = extract_y_frames_from_video(vp, FRAMES_PER_VIDEO)\n",
    "        if not frames_y:\n",
    "            continue\n",
    "        residuals = process_video_frames_to_residuals(frames_y)\n",
    "        for r in residuals:\n",
    "            if fp_sum is None:\n",
    "                fp_sum = np.zeros_like(r, dtype=np.float64)\n",
    "            fp_sum += r\n",
    "            count += 1\n",
    "        # free\n",
    "        del frames_y, residuals\n",
    "        gc.collect()\n",
    "\n",
    "    if fp_sum is None or count == 0:\n",
    "        print(f\"[!] Could not produce fingerprint for {device_name}\")\n",
    "        return device_name, None\n",
    "\n",
    "    fingerprint = (fp_sum / float(count)).astype(np.float32)\n",
    "    save_path = os.path.join(FINGERPRINT_DIR, f\"{device_name}_video_fingerprint.npy\")\n",
    "    np.save(save_path, fingerprint)\n",
    "    print(f\"[+] Saved fingerprint for {device_name}: {save_path} shape={fingerprint.shape} (avg over {count} frames)\")\n",
    "    return device_name, save_path\n",
    "\n",
    "def main():\n",
    "    device_name = \"Samsung S23 5g\"   # <-- change this to your device folder name\n",
    "    print(f\"Generating fingerprint for: {device_name}\")\n",
    "    dev, path = compute_device_fingerprint(device_name)\n",
    "\n",
    "    if path is None:\n",
    "        print(f\"[!] Fingerprint generation failed for {device_name}\")\n",
    "    else:\n",
    "        print(f\"[+] Fingerprint generated and saved at: {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "'''\n",
    "def main():\n",
    "    devices = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "    if not devices:\n",
    "        print(\"[!] No device folders found in DATA_DIR\")\n",
    "        return\n",
    "\n",
    "    print(\"Devices:\", devices)\n",
    "    print(\"\\n[Running sequential mode to avoid Windows multiprocessing hang]\\n\")\n",
    "\n",
    "    results = []\n",
    "    for dev in devices:\n",
    "        print(f\"\\nProcessing fingerprint for: {dev}\")\n",
    "        result = compute_device_fingerprint(dev)\n",
    "        results.append(result)\n",
    "\n",
    "    # summary\n",
    "    print(\"\\n======== SUMMARY ========\")\n",
    "    for dev, path in results:\n",
    "        if path is None:\n",
    "            print(f\"[!] Fingerprint failed for {dev}\")\n",
    "        else:\n",
    "            print(f\"[+] Fingerprint ready: {dev} -> {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d383bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking videos for iphone15: 3 files found ---\n",
      "IMG_5454.mp4 -> Pred: iphone15 (hybrid=0.897) | top2: [('iphone15', 0.8970188550468834), ('OnePlus Nord CE4', 0.7)]\n",
      "IMG_5455.mp4 -> Pred: iphone15 (hybrid=1.000) | top2: [('iphone15', 1.0), ('OnePlus Nord CE4', 0.2976830026209783)]\n",
      "IMG_5456 copy.mp4 -> Pred: iphone15 (hybrid=1.000) | top2: [('iphone15', 1.0), ('OnePlus Nord CE4', 0.0038381056888906733)]\n",
      "\n",
      "--- Checking videos for OnePlus Nord CE4: 4 files found ---\n",
      "VID20251030112624.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.818) | top2: [('OnePlus Nord CE4', 0.8178160013724185), ('Samsung S23 5g', 0.7264715105406965)]\n",
      "VID20251030112641.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.943) | top2: [('OnePlus Nord CE4', 0.9430856511899364), ('Samsung S23 5g', 0.7)]\n",
      "VID20251030112807.mp4 -> Pred: iphone15 (hybrid=0.739) | top2: [('iphone15', 0.7386631117895808), ('Samsung S23 5g', 0.7)]\n",
      "VID20251030112925.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.700) | top2: [('OnePlus Nord CE4', 0.7), ('Samsung S23 5g', 0.6277473701464055)]\n",
      "\n",
      "--- Checking videos for Samsung S21 FE: 2 files found ---\n",
      "20251017_194729.mp4 -> Pred: Samsung S23 5g (hybrid=0.818) | top2: [('Samsung S23 5g', 0.8182961409933043), ('Samsung S21 FE', 0.30000000000000004)]\n",
      "20251017_202243.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.801) | top2: [('OnePlus Nord CE4', 0.8014023150883169), ('iphone15', 0.6335027057239399)]\n",
      "\n",
      "--- Checking videos for Samsung S23 5g: 4 files found ---\n",
      "20250712_120212.mp4 -> Pred: Samsung S23 5g (hybrid=0.866) | top2: [('Samsung S23 5g', 0.8655375409043881), ('OnePlus Nord CE4', 0.7059429668202086)]\n",
      "20250914_130351.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.906) | top2: [('OnePlus Nord CE4', 0.9061817853478866), ('Samsung S23 5g', 0.8940352639317453)]\n",
      "20250927_205316.mp4 -> Pred: Samsung S23 5g (hybrid=0.907) | top2: [('Samsung S23 5g', 0.9074246385331509), ('iphone15', 0.6121132950075221)]\n",
      "20250930_173755.mp4 -> Pred: Samsung S23 5g (hybrid=0.700) | top2: [('Samsung S23 5g', 0.7), ('OnePlus Nord CE4', 0.6381558992056454)]\n",
      "\n",
      "======== FINAL RESULTS ========\n",
      "iphone15 has 3 videos: correct categorizations = 3/3\n",
      "OnePlus Nord CE4 has 4 videos: correct categorizations = 3/4\n",
      "Samsung S21 FE has 2 videos: correct categorizations = 0/2\n",
      "Samsung S23 5g has 4 videos: correct categorizations = 3/4\n",
      "\n",
      "Overall Accuracy: 9/13\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "match_query_videos_fast.py\n",
    "- Load fingerprints and classify query videos using hybrid PCE+NCC\n",
    "- Query extraction uses BM3D mild on Y-channel, resized to 1024x768\n",
    "- FRAMES_PER_VIDEO_QUERY set to 6 for speed\n",
    "\"\"\"\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from bm3d import bm3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------- CONFIG -------\n",
    "DATA_DIR = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "FINGERPRINT_DIR = os.path.join(os.path.dirname(DATA_DIR), \"fingerprints\")\n",
    "DEVICES = ['iphone15', 'OnePlus Nord CE4', 'Samsung S21 FE', 'Samsung S23 5g']\n",
    "TARGET_WIDTH = 1024\n",
    "TARGET_HEIGHT = 768\n",
    "FRAMES_PER_VIDEO_QUERY = 6\n",
    "BM3D_SIGMA = 2.6 / 255.0 #(2.5 was giving 9/13)\n",
    "ALPHA = 0.7   # weight for PCE in hybrid score\n",
    "EPS = 1e-12\n",
    "# ----------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_w, target_h):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_w, target_h), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_w, target_h))\n",
    "    new_img.paste(img, ((target_w - img.width) // 2, (target_h - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "def extract_query_prnu(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total == 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "    indices = np.linspace(0, total - 1, FRAMES_PER_VIDEO_QUERY, dtype=int)\n",
    "    residuals = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "        ycc = cv2.cvtColor(resized, cv2.COLOR_RGB2YCrCb)\n",
    "        y = ycc[:, :, 0].astype(np.float32) / 255.0\n",
    "        try:\n",
    "            den = bm3d(y, BM3D_SIGMA, stage_arg=bm3d.STAGE_ALL)\n",
    "        except Exception:\n",
    "            den = bm3d(y, BM3D_SIGMA)\n",
    "        resid = y - den\n",
    "        residuals.append(resid.astype(np.float32))\n",
    "    cap.release()\n",
    "    if not residuals:\n",
    "        return None\n",
    "    return np.mean(residuals, axis=0).astype(np.float32)\n",
    "\n",
    "def ncc_score(a, b):\n",
    "    a_flat = a.ravel()\n",
    "    b_flat = b.ravel()\n",
    "    a_z = a_flat - a_flat.mean()\n",
    "    b_z = b_flat - b_flat.mean()\n",
    "    denom = np.sqrt((a_z**2).sum() * (b_z**2).sum()) + EPS\n",
    "    return float((a_z * b_z).sum() / denom)\n",
    "\n",
    "def compute_pce(a, b):\n",
    "    # For speed\n",
    "    H, W = a.shape\n",
    "    fa = a - a.mean()\n",
    "    fb = b - b.mean()\n",
    "    FA = np.fft.fft2(fa)\n",
    "    FB = np.fft.fft2(fb)\n",
    "    corr = np.fft.ifft2(FA * np.conj(FB)).real\n",
    "    corr = np.fft.fftshift(corr)\n",
    "    peak = corr.max()\n",
    "    peak_idx = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "    # exclude small neighborhood\n",
    "    rx = max(3, min(H // 40, 10))\n",
    "    ry = max(3, min(W // 40, 10))\n",
    "    y0, x0 = peak_idx\n",
    "    mask = np.ones_like(corr, dtype=bool)\n",
    "    y1 = max(0, y0 - rx); y2 = min(H, y0 + rx + 1)\n",
    "    x1 = max(0, x0 - ry); x2 = min(W, x0 + ry + 1)\n",
    "    mask[y1:y2, x1:x2] = False\n",
    "    outside = corr[mask]\n",
    "    outside_energy = (outside**2).mean() if outside.size > 0 else EPS\n",
    "    pce = (peak**2) / (outside_energy + EPS)\n",
    "    return float(pce)\n",
    "\n",
    "def load_fingerprints(devices):\n",
    "    fps = {}\n",
    "    for d in devices:\n",
    "        p = os.path.join(FINGERPRINT_DIR, f\"{d}_video_fingerprint.npy\")\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"[!] Fingerprint missing for {d}: {p}\")\n",
    "            fps[d] = None\n",
    "        else:\n",
    "            fps[d] = np.load(p).astype(np.float32)\n",
    "            if fps[d].shape != (TARGET_HEIGHT, TARGET_WIDTH):\n",
    "                print(f\"[!] Warning: {d} fingerprint shape {fps[d].shape} != expected {(TARGET_HEIGHT, TARGET_WIDTH)}\")\n",
    "    return fps\n",
    "\n",
    "def hybrid_scores(query_prnu, fingerprints):\n",
    "    pce_vals = {}\n",
    "    ncc_vals = {}\n",
    "    for d, fp in fingerprints.items():\n",
    "        if fp is None:\n",
    "            pce_vals[d] = -1.0\n",
    "            ncc_vals[d] = -1.0\n",
    "            continue\n",
    "        pce_vals[d] = compute_pce(query_prnu, fp)\n",
    "        ncc_vals[d] = ncc_score(query_prnu, fp)\n",
    "    # normalize\n",
    "    pce_arr = np.array([max(0.0, pce_vals[d]) for d in fingerprints.keys()], dtype=np.float32)\n",
    "    ncc_arr = np.array([ncc_vals[d] for d in fingerprints.keys()], dtype=np.float32)\n",
    "    pce_min, pce_max = float(pce_arr.min()), float(pce_arr.max())\n",
    "    denom_pce = (pce_max - pce_min) if (pce_max - pce_min) > EPS else 1.0\n",
    "    ncc_min, ncc_max = float(ncc_arr.min()), float(ncc_arr.max())\n",
    "    denom_ncc = (ncc_max - ncc_min) if (ncc_max - ncc_min) > EPS else 1.0\n",
    "    pce_norm = {d: float((max(0.0, pce_vals[d]) - pce_min) / denom_pce) for d in fingerprints.keys()}\n",
    "    ncc_norm = {d: float((ncc_vals[d] - ncc_min) / denom_ncc) for d in fingerprints.keys()}\n",
    "    hybrid = {d: ALPHA * pce_norm[d] + (1.0 - ALPHA) * ncc_norm[d] for d in fingerprints.keys()}\n",
    "    return hybrid, pce_vals, ncc_vals\n",
    "\n",
    "def main():\n",
    "    fingerprints = load_fingerprints(DEVICES)\n",
    "    results = {d: {\"correct\": 0, \"total\": 0} for d in DEVICES}\n",
    "\n",
    "    for dev in DEVICES:\n",
    "        query_folder = os.path.join(DATA_DIR, dev, \"videos\", \"query_set\")\n",
    "        qpaths = sorted(glob.glob(os.path.join(query_folder, \"*.mp4\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.mov\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.avi\")))\n",
    "        print(f\"\\n--- Checking videos for {dev}: {len(qpaths)} files found ---\")\n",
    "        for q in qpaths:\n",
    "            query_prnu = extract_query_prnu(q)\n",
    "            if query_prnu is None:\n",
    "                print(f\"[!] Could not extract PRNU for {q}\")\n",
    "                continue\n",
    "            hybrid, pce_vals, ncc_vals = hybrid_scores(query_prnu, fingerprints)\n",
    "            predicted = max(hybrid, key=hybrid.get)\n",
    "            results[dev][\"total\"] += 1\n",
    "            if predicted == dev:\n",
    "                results[dev][\"correct\"] += 1\n",
    "            # print concise info\n",
    "            top_k = sorted(hybrid.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "            print(f\"{os.path.basename(q)} -> Pred: {predicted} (hybrid={hybrid[predicted]:.3f}) | top2: {top_k}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n======== FINAL RESULTS ========\")\n",
    "    total_correct = 0\n",
    "    total_videos = 0\n",
    "    for d, vals in results.items():\n",
    "        c = vals[\"correct\"]; t = vals[\"total\"]\n",
    "        total_correct += c; total_videos += t\n",
    "        print(f\"{d} has {t} videos: correct categorizations = {c}/{t}\")\n",
    "    print(f\"\\nOverall Accuracy: {total_correct}/{total_videos}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94e0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking videos for iphone15: 3 files found ---\n",
      "[INFO] IMG_5454.mp4 -> median estimated sigma = 0.003922\n",
      "IMG_5454.mp4 -> Pred: iphone15 (hybrid=1.000) | top2: [('iphone15', 1.0), ('Samsung S23 5g', 0.6997091065168597)]\n",
      "[INFO] IMG_5455.mp4 -> median estimated sigma = 0.003922\n",
      "IMG_5455.mp4 -> Pred: iphone15 (hybrid=1.000) | top2: [('iphone15', 1.0), ('OnePlus Nord CE4', 0.3791451073468297)]\n",
      "[INFO] IMG_5456 copy.mp4 -> median estimated sigma = 0.003922\n",
      "IMG_5456 copy.mp4 -> Pred: iphone15 (hybrid=1.000) | top2: [('iphone15', 1.0), ('Samsung S21 FE', 0.005413854386907948)]\n",
      "\n",
      "--- Checking videos for OnePlus Nord CE4: 4 files found ---\n",
      "[INFO] VID20251030112624.mp4 -> median estimated sigma = 0.003922\n",
      "VID20251030112624.mp4 -> Pred: Samsung S23 5g (hybrid=0.762) | top2: [('Samsung S23 5g', 0.7615750160454334), ('OnePlus Nord CE4', 0.6964218053709379)]\n",
      "[INFO] VID20251030112641.mp4 -> median estimated sigma = 0.003922\n",
      "VID20251030112641.mp4 -> Pred: Samsung S23 5g (hybrid=0.903) | top2: [('Samsung S23 5g', 0.9030721690083012), ('OnePlus Nord CE4', 0.6144818480014334)]\n",
      "[INFO] VID20251030112807.mp4 -> median estimated sigma = 0.003922\n",
      "VID20251030112807.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.991) | top2: [('OnePlus Nord CE4', 0.9906694502415516), ('iphone15', 0.8489587493001239)]\n",
      "[INFO] VID20251030112925.mp4 -> median estimated sigma = 0.003922\n",
      "VID20251030112925.mp4 -> Pred: Samsung S23 5g (hybrid=0.878) | top2: [('Samsung S23 5g', 0.8782800800094412), ('iphone15', 0.8576535411434781)]\n",
      "\n",
      "--- Checking videos for Samsung S21 FE: 2 files found ---\n",
      "[INFO] 20251017_194729.mp4 -> median estimated sigma = 0.003922\n",
      "20251017_194729.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.700) | top2: [('OnePlus Nord CE4', 0.7), ('Samsung S21 FE', 0.3626307937918981)]\n",
      "[INFO] 20251017_202243.mp4 -> median estimated sigma = 0.003922\n",
      "20251017_202243.mp4 -> Pred: Samsung S23 5g (hybrid=0.966) | top2: [('Samsung S23 5g', 0.9655414700225302), ('iphone15', 0.5864635365370714)]\n",
      "\n",
      "--- Checking videos for Samsung S23 5g: 4 files found ---\n",
      "[INFO] 20250712_120212.mp4 -> median estimated sigma = 0.003922\n",
      "20250712_120212.mp4 -> Pred: Samsung S23 5g (hybrid=0.848) | top2: [('Samsung S23 5g', 0.8476328918260851), ('OnePlus Nord CE4', 0.8349193102152428)]\n",
      "[INFO] 20250914_130351.mp4 -> median estimated sigma = 0.003922\n",
      "20250914_130351.mp4 -> Pred: Samsung S23 5g (hybrid=1.000) | top2: [('Samsung S23 5g', 1.0), ('OnePlus Nord CE4', 0.6913175163749818)]\n",
      "[INFO] 20250927_205316.mp4 -> median estimated sigma = 0.003922\n",
      "20250927_205316.mp4 -> Pred: iphone15 (hybrid=0.821) | top2: [('iphone15', 0.8211790279954002), ('OnePlus Nord CE4', 0.7)]\n",
      "[INFO] 20250930_173755.mp4 -> median estimated sigma = 0.003922\n",
      "20250930_173755.mp4 -> Pred: OnePlus Nord CE4 (hybrid=0.886) | top2: [('OnePlus Nord CE4', 0.8856716872445647), ('iphone15', 0.8105797362014415)]\n",
      "\n",
      "======== FINAL RESULTS ========\n",
      "iphone15 has 3 videos: correct categorizations = 3/3\n",
      "OnePlus Nord CE4 has 4 videos: correct categorizations = 1/4\n",
      "Samsung S21 FE has 2 videos: correct categorizations = 0/2\n",
      "Samsung S23 5g has 4 videos: correct categorizations = 2/4\n",
      "\n",
      "Overall Accuracy: 6/13\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from bm3d import bm3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------- CONFIG -------\n",
    "DATA_DIR = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "FINGERPRINT_DIR = os.path.join(os.path.dirname(DATA_DIR), \"fingerprints\")\n",
    "DEVICES = ['iphone15', 'OnePlus Nord CE4', 'Samsung S21 FE', 'Samsung S23 5g']\n",
    "TARGET_WIDTH = 1024\n",
    "TARGET_HEIGHT = 768\n",
    "FRAMES_PER_VIDEO_QUERY = 6\n",
    "\n",
    "# Adaptive BM3D bounds (in image-value units where images are in [0,1])\n",
    "MIN_SIGMA = 1.0 / 255.0    # mild floor\n",
    "MAX_SIGMA = 3.0 / 255.0    # avoid over-denoising\n",
    "ALPHA = 0.7   # weight for PCE in hybrid score\n",
    "EPS = 1e-12\n",
    "# ----------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_w, target_h):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_w, target_h), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_w, target_h))\n",
    "    new_img.paste(img, ((target_w - img.width) // 2, (target_h - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "def estimate_frame_noise_sigma(imgf):\n",
    "    \"\"\"\n",
    "    Robust noise estimate for a single grayscale image in [0,1].\n",
    "    Uses MAD on a small high-pass (image - gaussian_blur) map.\n",
    "    Returns sigma estimate (float).\n",
    "    \"\"\"\n",
    "    # small Gaussian blur to remove high-frequency noise, keep low-freq content\n",
    "    blur = cv2.GaussianBlur(imgf.astype(np.float32), (3, 3), 0)\n",
    "    high = imgf - blur\n",
    "    mad = np.median(np.abs(high))\n",
    "    # Convert MAD to sigma estimate (for Gaussian noise)\n",
    "    sigma_est = mad / 0.6745\n",
    "    # clamp to realistic bounds\n",
    "    sigma_est = float(max(MIN_SIGMA, min(MAX_SIGMA, sigma_est)))\n",
    "    return sigma_est\n",
    "\n",
    "def extract_query_prnu(video_path):\n",
    "    \"\"\"\n",
    "    Extract query PRNU using adaptive BM3D sigma:\n",
    "    1) sample FRAMES_PER_VIDEO_QUERY frames\n",
    "    2) estimate sigma per frame via estimate_frame_noise_sigma\n",
    "    3) use median sigma across frames for BM3D denoising for that video\n",
    "    4) residuals = img - denoised; return mean residual\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total == 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    indices = np.linspace(0, total - 1, FRAMES_PER_VIDEO_QUERY, dtype=int)\n",
    "    frames = []\n",
    "    sigmas = []\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "        ycc = cv2.cvtColor(resized, cv2.COLOR_RGB2YCrCb)\n",
    "        y = ycc[:, :, 0].astype(np.float32) / 255.0  # normalized [0,1]\n",
    "        frames.append(y)\n",
    "        sigmas.append(estimate_frame_noise_sigma(y))\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return None\n",
    "\n",
    "    # Use median sigma for stability\n",
    "    median_sigma = float(np.median(sigmas))\n",
    "    # final safety clamps (redundant but explicit)\n",
    "    median_sigma = max(MIN_SIGMA, min(MAX_SIGMA, median_sigma))\n",
    "\n",
    "    print(f\"[INFO] {os.path.basename(video_path)} -> median estimated sigma = {median_sigma:.6f}\")\n",
    "\n",
    "    residuals = []\n",
    "    for y in frames:\n",
    "        try:\n",
    "            den = bm3d(y, median_sigma, stage_arg=bm3d.STAGE_ALL)\n",
    "        except Exception:\n",
    "            den = bm3d(y, median_sigma)\n",
    "        resid = y - den\n",
    "        residuals.append(resid.astype(np.float32))\n",
    "\n",
    "    prnu = np.mean(residuals, axis=0).astype(np.float32)\n",
    "    return prnu\n",
    "\n",
    "def ncc_score(a, b):\n",
    "    a_flat = a.ravel()\n",
    "    b_flat = b.ravel()\n",
    "    a_z = a_flat - a_flat.mean()\n",
    "    b_z = b_flat - b_flat.mean()\n",
    "    denom = np.sqrt((a_z**2).sum() * (b_z**2).sum()) + EPS\n",
    "    return float((a_z * b_z).sum() / denom)\n",
    "\n",
    "def compute_pce(a, b):\n",
    "    # For speed\n",
    "    H, W = a.shape\n",
    "    fa = a - a.mean()\n",
    "    fb = b - b.mean()\n",
    "    FA = np.fft.fft2(fa)\n",
    "    FB = np.fft.fft2(fb)\n",
    "    corr = np.fft.ifft2(FA * np.conj(FB)).real\n",
    "    corr = np.fft.fftshift(corr)\n",
    "    peak = corr.max()\n",
    "    peak_idx = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "    # exclude small neighborhood\n",
    "    rx = max(3, min(H // 40, 10))\n",
    "    ry = max(3, min(W // 40, 10))\n",
    "    y0, x0 = peak_idx\n",
    "    mask = np.ones_like(corr, dtype=bool)\n",
    "    y1 = max(0, y0 - rx); y2 = min(H, y0 + rx + 1)\n",
    "    x1 = max(0, x0 - ry); x2 = min(W, x0 + ry + 1)\n",
    "    mask[y1:y2, x1:x2] = False\n",
    "    outside = corr[mask]\n",
    "    outside_energy = (outside**2).mean() if outside.size > 0 else EPS\n",
    "    pce = (peak**2) / (outside_energy + EPS)\n",
    "    return float(pce)\n",
    "\n",
    "def load_fingerprints(devices):\n",
    "    fps = {}\n",
    "    for d in devices:\n",
    "        p = os.path.join(FINGERPRINT_DIR, f\"{d}_video_fingerprint.npy\")\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"[!] Fingerprint missing for {d}: {p}\")\n",
    "            fps[d] = None\n",
    "        else:\n",
    "            fps[d] = np.load(p).astype(np.float32)\n",
    "            if fps[d].shape != (TARGET_HEIGHT, TARGET_WIDTH):\n",
    "                print(f\"[!] Warning: {d} fingerprint shape {fps[d].shape} != expected {(TARGET_HEIGHT, TARGET_WIDTH)}\")\n",
    "    return fps\n",
    "\n",
    "def hybrid_scores(query_prnu, fingerprints):\n",
    "    pce_vals = {}\n",
    "    ncc_vals = {}\n",
    "    for d, fp in fingerprints.items():\n",
    "        if fp is None:\n",
    "            pce_vals[d] = -1.0\n",
    "            ncc_vals[d] = -1.0\n",
    "            continue\n",
    "        pce_vals[d] = compute_pce(query_prnu, fp)\n",
    "        ncc_vals[d] = ncc_score(query_prnu, fp)\n",
    "    # normalize\n",
    "    pce_arr = np.array([max(0.0, pce_vals[d]) for d in fingerprints.keys()], dtype=np.float32)\n",
    "    ncc_arr = np.array([ncc_vals[d] for d in fingerprints.keys()], dtype=np.float32)\n",
    "    pce_min, pce_max = float(pce_arr.min()), float(pce_arr.max())\n",
    "    denom_pce = (pce_max - pce_min) if (pce_max - pce_min) > EPS else 1.0\n",
    "    ncc_min, ncc_max = float(ncc_arr.min()), float(ncc_arr.max())\n",
    "    denom_ncc = (ncc_max - ncc_min) if (ncc_max - ncc_min) > EPS else 1.0\n",
    "    pce_norm = {d: float((max(0.0, pce_vals[d]) - pce_min) / denom_pce) for d in fingerprints.keys()}\n",
    "    ncc_norm = {d: float((ncc_vals[d] - ncc_min) / denom_ncc) for d in fingerprints.keys()}\n",
    "    hybrid = {d: ALPHA * pce_norm[d] + (1.0 - ALPHA) * ncc_norm[d] for d in fingerprints.keys()}\n",
    "    return hybrid, pce_vals, ncc_vals\n",
    "\n",
    "def main():\n",
    "    fingerprints = load_fingerprints(DEVICES)\n",
    "    results = {d: {\"correct\": 0, \"total\": 0} for d in DEVICES}\n",
    "\n",
    "    for dev in DEVICES:\n",
    "        query_folder = os.path.join(DATA_DIR, dev, \"videos\", \"query_set\")\n",
    "        qpaths = sorted(glob.glob(os.path.join(query_folder, \"*.mp4\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.mov\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.avi\")))\n",
    "        print(f\"\\n--- Checking videos for {dev}: {len(qpaths)} files found ---\")\n",
    "        for q in qpaths:\n",
    "            query_prnu = extract_query_prnu(q)\n",
    "            if query_prnu is None:\n",
    "                print(f\"[!] Could not extract PRNU for {q}\")\n",
    "                continue\n",
    "            hybrid, pce_vals, ncc_vals = hybrid_scores(query_prnu, fingerprints)\n",
    "            predicted = max(hybrid, key=hybrid.get)\n",
    "            results[dev][\"total\"] += 1\n",
    "            if predicted == dev:\n",
    "                results[dev][\"correct\"] += 1\n",
    "            # print concise info\n",
    "            top_k = sorted(hybrid.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "            print(f\"{os.path.basename(q)} -> Pred: {predicted} (hybrid={hybrid[predicted]:.3f}) | top2: {top_k}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n======== FINAL RESULTS ========\")\n",
    "    total_correct = 0\n",
    "    total_videos = 0\n",
    "    for d, vals in results.items():\n",
    "        c = vals[\"correct\"]; t = vals[\"total\"]\n",
    "        total_correct += c; total_videos += t\n",
    "        print(f\"{d} has {t} videos: correct categorizations = {c}/{t}\")\n",
    "    print(f\"\\nOverall Accuracy: {total_correct}/{total_videos}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ceff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking videos for iphone15: found 3 files ---\n",
      "IMG_5454.mp4 -> Pred: iphone15 (top PCE:96.71, NCC:0.0102) ; 2nd:OnePlus Nord CE4 PCE:46.35\n",
      "IMG_5455.mp4 -> Pred: iphone15 (top PCE:56.53, NCC:0.0096) ; 2nd:OnePlus Nord CE4 PCE:46.67\n",
      "IMG_5456 copy.mp4 -> Pred: iphone15 (top PCE:12114.03, NCC:0.1941) ; 2nd:Samsung S23 5g PCE:45.87\n",
      "\n",
      "--- Checking videos for OnePlus Nord CE4: found 4 files ---\n",
      "VID20251030112624.mp4 -> Pred: OnePlus Nord CE4 (top PCE:57.34, NCC:0.0010) ; 2nd:Samsung S23 5g PCE:51.87\n",
      "VID20251030112641.mp4 -> Pred: OnePlus Nord CE4 (top PCE:51.89, NCC:0.0055) ; 2nd:Samsung S23 5g PCE:48.20\n",
      "VID20251030112807.mp4 -> Pred: OnePlus Nord CE4 (top PCE:45.16, NCC:0.0015) ; 2nd:Samsung S23 5g PCE:46.75\n",
      "VID20251030112925.mp4 -> Pred: OnePlus Nord CE4 (top PCE:46.39, NCC:0.0003) ; 2nd:Samsung S23 5g PCE:47.67\n",
      "\n",
      "--- Checking videos for Samsung S21 FE: found 2 files ---\n",
      "20251017_194729.mp4 -> Pred: OnePlus Nord CE4 (top PCE:50.48, NCC:-0.0005) ; 2nd:iphone15 PCE:47.25\n",
      "20251017_202243.mp4 -> Pred: OnePlus Nord CE4 (top PCE:44.19, NCC:-0.0001) ; 2nd:iphone15 PCE:39.86\n",
      "\n",
      "--- Checking videos for Samsung S23 5g: found 4 files ---\n",
      "20250712_120212.mp4 -> Pred: iphone15 (top PCE:51.45, NCC:0.0024) ; 2nd:OnePlus Nord CE4 PCE:41.95\n",
      "20250914_130351.mp4 -> Pred: Samsung S23 5g (top PCE:43.55, NCC:0.0010) ; 2nd:OnePlus Nord CE4 PCE:44.10\n",
      "20250927_205316.mp4 -> Pred: OnePlus Nord CE4 (top PCE:45.00, NCC:0.0022) ; 2nd:iphone15 PCE:37.67\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mextract_query_prnu\u001b[39m\u001b[34m(video_path)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     den = bm3d(y, BM3D_SIGMA, stage_arg=\u001b[43mbm3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTAGE_ALL\u001b[49m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'STAGE_ALL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOverall Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_correct\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_videos\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 165\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Checking videos for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(qpaths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m qpaths:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     query_prnu = \u001b[43mextract_query_prnu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_prnu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    167\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not extract PRNU for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mextract_query_prnu\u001b[39m\u001b[34m(video_path)\u001b[39m\n\u001b[32m     58\u001b[39m     den = bm3d(y, BM3D_SIGMA, stage_arg=bm3d.STAGE_ALL)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     den = \u001b[43mbm3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBM3D_SIGMA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m resid = y - den\n\u001b[32m     62\u001b[39m residuals.append(resid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Khushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bm3d\\__init__.py:223\u001b[39m, in \u001b[36mbm3d\u001b[39m\u001b[34m(z, sigma_psd, profile, stage_arg, blockmatches)\u001b[39m\n\u001b[32m    221\u001b[39m         y_hat, bm = _bm4d.bm4d(z, sigma_psd, converted_profile, stage_arg, blockmatches)\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m         y_hat = \u001b[43m_bm4d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbm4d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_psd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_profile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblockmatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Remove useless dimension if only single output\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_count == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Khushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bm4d\\__init__.py:255\u001b[39m, in \u001b[36mbm4d\u001b[39m\u001b[34m(z, sigma_psd, profile, stage_arg, blockmatches)\u001b[39m\n\u001b[32m    251\u001b[39m t_forward, t_inverse, hadper_trans_single_den, \\\n\u001b[32m    252\u001b[39m     inverse_hadper_trans_single_den, wwin3d = _get_transforms(pro, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# Wiener filtering\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m y_hat, bm_out_wie = \u001b[43mwie_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsd_blur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqshifts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhadper_trans_single_den\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m                            \u001b[49m\u001b[43minverse_hadper_trans_single_den\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwwin3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblockmatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbm_in_wie\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Residual denoising, Wiener\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pro.denoise_residual:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Khushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bm4d\\bm4d_ctypes.py:736\u001b[39m, in \u001b[36mbm4d_wie\u001b[39m\u001b[34m(z, psd, pro, t_forward, t_inverse, qshifts, hadper_trans_single_den, inverse_hadper_trans_single_den, wwin3d, ref, refilter, blockmatches)\u001b[39m\n\u001b[32m    732\u001b[39m stack_storage_size = get_stack_storage_size(z.shape, pro.step_wiener)\n\u001b[32m    734\u001b[39m matchtables = get_blockmatch_storage(blockmatches, pro.max_stack_size_wiener, stack_storage_size)\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[43mfunc_wie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_psd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_est\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m         \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatchtables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatchtables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatchtables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(z_shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    740\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(z_shape[\u001b[32m1\u001b[39m]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "match_query_videos_hybrid.py\n",
    "- Loads fingerprints from fingerprints/{device}_video_fingerprint.npy\n",
    "- Extracts PRNU from each query video using SAME BM3D+Y extraction (resizing/padding to 512x384)\n",
    "- Computes PCE and NCC between query residual and each device fingerprint\n",
    "- Uses hybrid score: 0.7*PCE_norm + 0.3*NCC_norm to pick predicted device\n",
    "- Prints results in your requested format.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from bm3d import bm3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- CONFIG (match generate script) --------\n",
    "DATA_DIR = r\"C:\\Users\\Khushi\\prnu-camera-source-detection\\data\"\n",
    "FINGERPRINT_DIR = os.path.join(os.path.dirname(DATA_DIR), \"fingerprints\")\n",
    "DEVICES = ['iphone15', 'OnePlus Nord CE4', 'Samsung S21 FE', 'Samsung S23 5g']\n",
    "TARGET_WIDTH = 1024\n",
    "TARGET_HEIGHT = 768\n",
    "FRAMES_PER_VIDEO = 50\n",
    "BATCH_SIZE = 15\n",
    "BM3D_SIGMA = 2.5 / 255.0\n",
    "ALPHA = 0.7  # weight for PCE in hybrid score\n",
    "EPS = 1e-12\n",
    "# ------------------------------------------------\n",
    "\n",
    "def resize_with_padding(img_np, target_w, target_h):\n",
    "    img = Image.fromarray(img_np)\n",
    "    img.thumbnail((target_w, target_h), Image.LANCZOS)\n",
    "    new_img = Image.new(\"RGB\", (target_w, target_h))\n",
    "    new_img.paste(img, ((target_w - img.width) // 2, (target_h - img.height) // 2))\n",
    "    return np.array(new_img, dtype=np.uint8)\n",
    "\n",
    "def extract_query_prnu(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total == 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "    indices = np.linspace(0, total-1, FRAMES_PER_VIDEO, dtype=int)\n",
    "    residuals = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized = resize_with_padding(rgb, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "        ycc = cv2.cvtColor(resized, cv2.COLOR_RGB2YCrCb)\n",
    "        y = ycc[:, :, 0].astype(np.float32) / 255.0\n",
    "        try:\n",
    "            den = bm3d(y, BM3D_SIGMA, stage_arg=bm3d.STAGE_ALL)\n",
    "        except Exception:\n",
    "            den = bm3d(y, BM3D_SIGMA)\n",
    "        resid = y - den\n",
    "        residuals.append(resid)\n",
    "    cap.release()\n",
    "    if not residuals:\n",
    "        return None\n",
    "    prnu = np.mean(residuals, axis=0).astype(np.float32)\n",
    "    return prnu\n",
    "\n",
    "def ncc_score(a, b):\n",
    "    # a,b floats same shape\n",
    "    a_flat = a.ravel()\n",
    "    b_flat = b.ravel()\n",
    "    a_z = a_flat - a_flat.mean()\n",
    "    b_z = b_flat - b_flat.mean()\n",
    "    denom = np.sqrt((a_z**2).sum() * (b_z**2).sum()) + EPS\n",
    "    return float((a_z * b_z).sum() / denom)\n",
    "\n",
    "def compute_pce(a, b):\n",
    "    \"\"\"\n",
    "    Approximate PCE:\n",
    "    - compute cross-correlation via FFT\n",
    "    - find peak value\n",
    "    - compute energy of correlation excluding small neighborhood around peak\n",
    "    - return peak^2 / mean(outside_energy)\n",
    "    \"\"\"\n",
    "    # both a and b are floats (residuals), same shape\n",
    "    H, W = a.shape\n",
    "    # zero-mean\n",
    "    fa = a - a.mean()\n",
    "    fb = b - b.mean()\n",
    "    # compute FFTs\n",
    "    FA = np.fft.fft2(fa)\n",
    "    FB = np.fft.fft2(fb)\n",
    "    corr = np.fft.ifft2(FA * np.conj(FB))\n",
    "    corr = np.fft.fftshift(corr.real)\n",
    "    # find peak\n",
    "    peak = corr.max()\n",
    "    # exclude small window around peak\n",
    "    peak_idx = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "    # define exclusion radius\n",
    "    rx = max(3, min(H//40, 10))\n",
    "    ry = max(3, min(W//40, 10))\n",
    "    y0, x0 = peak_idx\n",
    "    mask = np.ones_like(corr, dtype=bool)\n",
    "    y1 = max(0, y0 - rx); y2 = min(H, y0 + rx + 1)\n",
    "    x1 = max(0, x0 - ry); x2 = min(W, x0 + ry + 1)\n",
    "    mask[y1:y2, x1:x2] = False\n",
    "    outside = corr[mask]\n",
    "    # energy measures\n",
    "    outside_energy = (outside**2).mean() if outside.size > 0 else EPS\n",
    "    pce = (peak**2) / (outside_energy + EPS)\n",
    "    return float(pce)\n",
    "\n",
    "def load_fingerprints(devices):\n",
    "    fps = {}\n",
    "    for d in devices:\n",
    "        p = os.path.join(FINGERPRINT_DIR, f\"{d}_video_fingerprint.npy\")\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"[!] Fingerprint missing for {d}: {p}\")\n",
    "            fps[d] = None\n",
    "        else:\n",
    "            fps[d] = np.load(p).astype(np.float32)\n",
    "            # ensure shape matches target\n",
    "            if fps[d].shape != (TARGET_HEIGHT, TARGET_WIDTH):\n",
    "                print(f\"[!] Warning: fingerprint shape {fps[d].shape} for {d} doesn't match expected {(TARGET_HEIGHT, TARGET_WIDTH)}\")\n",
    "    return fps\n",
    "\n",
    "def hybrid_scores_for_query(query_prnu, fingerprints):\n",
    "    # compute raw PCE and NCC for each device\n",
    "    pce_vals = {}\n",
    "    ncc_vals = {}\n",
    "    for d, fp in fingerprints.items():\n",
    "        if fp is None:\n",
    "            pce_vals[d] = -1.0\n",
    "            ncc_vals[d] = -1.0\n",
    "            continue\n",
    "        pce_vals[d] = compute_pce(query_prnu, fp)\n",
    "        ncc_vals[d] = ncc_score(query_prnu, fp)\n",
    "    # normalize PCE (non-negative) and NCC across devices to [0,1]\n",
    "    pce_arr = np.array([max(0.0, pce_vals[d]) for d in fingerprints.keys()], dtype=np.float32)\n",
    "    ncc_arr = np.array([ncc_vals[d] for d in fingerprints.keys()], dtype=np.float32)\n",
    "    # PCE normalization\n",
    "    pce_min, pce_max = float(pce_arr.min()), float(pce_arr.max())\n",
    "    denom_pce = (pce_max - pce_min) if (pce_max - pce_min) > EPS else 1.0\n",
    "    pce_norm = {d: float((max(0.0, pce_vals[d]) - pce_min) / denom_pce) for d in fingerprints.keys()}\n",
    "    # NCC normalization (map from observed range to [0,1])\n",
    "    ncc_min, ncc_max = float(ncc_arr.min()), float(ncc_arr.max())\n",
    "    denom_ncc = (ncc_max - ncc_min) if (ncc_max - ncc_min) > EPS else 1.0\n",
    "    ncc_norm = {d: float((ncc_vals[d] - ncc_min) / denom_ncc) for d in fingerprints.keys()}\n",
    "    # hybrid score\n",
    "    hybrid = {d: ALPHA * pce_norm[d] + (1.0 - ALPHA) * ncc_norm[d] for d in fingerprints.keys()}\n",
    "    return hybrid, pce_vals, ncc_vals\n",
    "\n",
    "def main():\n",
    "    fingerprints = load_fingerprints(DEVICES)\n",
    "    results = {d: {\"correct\": 0, \"total\": 0} for d in DEVICES}\n",
    "\n",
    "    for dev in DEVICES:\n",
    "        query_folder = os.path.join(DATA_DIR, dev, \"videos\", \"query_set\")\n",
    "        qpaths = sorted(glob.glob(os.path.join(query_folder, \"*.mp4\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.mov\")) +\n",
    "                        glob.glob(os.path.join(query_folder, \"*.avi\")))\n",
    "        print(f\"\\n--- Checking videos for {dev}: found {len(qpaths)} files ---\")\n",
    "        for q in qpaths:\n",
    "            query_prnu = extract_query_prnu(q)\n",
    "            if query_prnu is None:\n",
    "                print(f\"Could not extract PRNU for {q}\")\n",
    "                continue\n",
    "            hybrid, pce_vals, ncc_vals = hybrid_scores_for_query(query_prnu, fingerprints)\n",
    "            predicted = max(hybrid, key=hybrid.get)\n",
    "            results[dev][\"total\"] += 1\n",
    "            if predicted == dev:\n",
    "                results[dev][\"correct\"] += 1\n",
    "            # Print short per-video line with PCE and NCC for top-2 (helpful)\n",
    "            sorted_by_score = sorted(hybrid.items(), key=lambda x: x[1], reverse=True)\n",
    "            top = sorted_by_score[0][0]\n",
    "            second = sorted_by_score[1][0] if len(sorted_by_score) > 1 else None\n",
    "            print(f\"{os.path.basename(q)} -> Pred: {predicted} (top PCE:{pce_vals[predicted]:.2f}, NCC:{ncc_vals[predicted]:.4f}) ; 2nd:{second} PCE:{pce_vals.get(second,0):.2f}\")\n",
    "\n",
    "    # Summary output in requested format\n",
    "    print(\"\\n======== FINAL RESULTS ========\")\n",
    "    total_correct = 0\n",
    "    total_videos = 0\n",
    "    for d, vals in results.items():\n",
    "        c = vals[\"correct\"]; t = vals[\"total\"]\n",
    "        total_correct += c; total_videos += t\n",
    "        print(f\"{d} has {t} videos: correct categorizations = {c}/{t}\")\n",
    "    print(f\"\\nOverall Accuracy: {total_correct}/{total_videos}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
