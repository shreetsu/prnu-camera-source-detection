{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATION\n",
    "# -----------------------------\n",
    "DATA_PATH = r\"prnu-camera-source-detection/data\"\n",
    "TARGET_SIZE = (1024, 768)\n",
    "THRESHOLD = 2\n",
    "N_SHARES = 5\n",
    "PRIME = 2**61 - 1\n",
    "SCALE = 1500\n",
    "\n",
    "# -----------------------------\n",
    "# PRNU Extraction\n",
    "# -----------------------------\n",
    "def extract_prnu(image_path: str, target_size: Tuple[int, int] = TARGET_SIZE) -> np.ndarray:\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"âš ï¸ Cannot read: {image_path}\")\n",
    "        return None\n",
    "    img = cv2.resize(img, target_size)\n",
    "    denoised = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    prnu = (img.astype(np.float32) - denoised.astype(np.float32))\n",
    "    prnu -= np.mean(prnu)\n",
    "    prnu /= (np.std(prnu) + 1e-8)\n",
    "    return prnu\n",
    "\n",
    "\n",
    "def compute_fingerprint(image_paths: List[str], target_size: Tuple[int, int] = TARGET_SIZE) -> np.ndarray:\n",
    "    prnus = [extract_prnu(p, target_size) for p in image_paths if extract_prnu(p) is not None]\n",
    "    if not prnus:\n",
    "        raise ValueError(\"No valid PRNU images found.\")\n",
    "    return np.mean(prnus, axis=0)\n",
    "\n",
    "# -----------------------------\n",
    "# Shamir Secret Sharing\n",
    "# -----------------------------\n",
    "def _eval_poly(coeffs: List[int], x: int, prime: int) -> int:\n",
    "    res, power = 0, 1\n",
    "    for c in coeffs:\n",
    "        res = (res + c * power) % prime\n",
    "        power = (power * x) % prime\n",
    "    return res\n",
    "\n",
    "def shamir_split(secret_int: int, t: int, n: int, prime: int = PRIME):\n",
    "    coeffs = [secret_int] + [int(np.random.randint(0, prime)) for _ in range(t - 1)]\n",
    "    shares = [(i, _eval_poly(coeffs, i, prime)) for i in range(1, n + 1)]\n",
    "    return shares\n",
    "\n",
    "def _lagrange_interpolate(points: List[Tuple[int, int]], prime: int = PRIME) -> int:\n",
    "    total = 0\n",
    "    for i, (xi, yi) in enumerate(points):\n",
    "        num, den = 1, 1\n",
    "        for j, (xj, _) in enumerate(points):\n",
    "            if i != j:\n",
    "                num = (num * (-xj)) % prime\n",
    "                den = (den * (xi - xj)) % prime\n",
    "        inv_den = pow(den, -1, prime)\n",
    "        total = (total + yi * num * inv_den) % prime\n",
    "    return total\n",
    "\n",
    "def shamir_reconstruct(points: List[Tuple[int, int]], prime: int = PRIME) -> int:\n",
    "    return _lagrange_interpolate(points, prime)\n",
    "\n",
    "# -----------------------------\n",
    "# Vector Encryption / Decryption\n",
    "# -----------------------------\n",
    "def encrypt_vector(vec: np.ndarray, threshold: int, shares: int) -> List[List[int]]:\n",
    "    scaled = np.round(vec * SCALE).astype(np.int64).flatten()\n",
    "    servers = [[] for _ in range(shares)]\n",
    "    for val in scaled:\n",
    "        val_mod = int(val % PRIME)\n",
    "        parts = shamir_split(val_mod, threshold, shares, PRIME)\n",
    "        for s_idx, (_, y) in enumerate(parts):\n",
    "            servers[s_idx].append(y)\n",
    "    return servers\n",
    "\n",
    "\n",
    "def reconstruct_vector(servers: List[List[int]], threshold: int, shape: Tuple[int, int]) -> np.ndarray:\n",
    "    chosen = [(i + 1, servers[i]) for i in range(threshold)]\n",
    "    reconstructed = []\n",
    "    for idx in range(len(servers[0])):\n",
    "        points = [(x, vals[idx]) for (x, vals) in chosen]\n",
    "        val = shamir_reconstruct(points, PRIME)\n",
    "        reconstructed.append(val)\n",
    "    arr = np.array(reconstructed, dtype=np.float64).reshape(shape)\n",
    "    return arr / SCALE\n",
    "\n",
    "# -----------------------------\n",
    "# Correlation\n",
    "# -----------------------------\n",
    "def corr2d(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    numerator = np.sum(x * y)\n",
    "    denominator = np.sqrt(np.sum(x**2) * np.sum(y**2))\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    return float(numerator / denominator)\n",
    "\n",
    "# -----------------------------\n",
    "# Pipeline\n",
    "# -----------------------------\n",
    "def process_phone(phone_path: str) -> Tuple[np.ndarray, List[str]]:\n",
    "    fp_imgs = glob(os.path.join(phone_path, \"images/fingerprint_set\", \"*.[jJ][pP][gG]\")) + \\\n",
    "               glob(os.path.join(phone_path, \"images/fingerprint_set\", \"*.[jJ][pP][eE][gG]\"))\n",
    "\n",
    "    q_imgs = glob(os.path.join(phone_path, \"images/query_set\", \"*.[jJ][pP][gG]\")) + \\\n",
    "              glob(os.path.join(phone_path, \"images/query_set\", \"*.[jJ][pP][eE][gG]\"))\n",
    "    if not fp_imgs:\n",
    "        raise ValueError(f\"No fingerprint images for {phone_path}\")\n",
    "    fingerprint = compute_fingerprint(fp_imgs)\n",
    "    return fingerprint, q_imgs\n",
    "\n",
    "\n",
    "def run_sss_prnu_pipeline(data_path: str):\n",
    "    phones = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "    fingerprints, servers_store, queries = {}, {}, {}\n",
    "\n",
    "    print(\"ðŸ”¹ Extracting fingerprints & encrypting...\\n\")\n",
    "    for phone in phones:\n",
    "        try:\n",
    "            fp, qset = process_phone(os.path.join(data_path, phone))\n",
    "            fingerprints[phone] = fp\n",
    "            queries[phone] = qset\n",
    "            servers_store[phone] = encrypt_vector(fp, THRESHOLD, N_SHARES)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping {phone}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Matching Report ---\")\n",
    "    results = []\n",
    "    for true_phone, qset in queries.items():\n",
    "        for q_img in qset:\n",
    "            q_prnu = extract_prnu(q_img)\n",
    "            if q_prnu is None:\n",
    "                continue\n",
    "            q_servers = encrypt_vector(q_prnu, THRESHOLD, N_SHARES)\n",
    "            q_recon = reconstruct_vector(q_servers, THRESHOLD, q_prnu.shape)\n",
    "\n",
    "            best_score, best_match = -1, None\n",
    "            for phone, fp_servers in servers_store.items():\n",
    "                fp_recon = reconstruct_vector(fp_servers, THRESHOLD, fingerprints[phone].shape)\n",
    "                score = corr2d(fp_recon, q_recon)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = phone\n",
    "\n",
    "            results.append((os.path.basename(q_img), true_phone, best_match, best_score))\n",
    "            print(f\"{os.path.basename(q_img)} | True: {true_phone:<15} | Predicted: {best_match:<15} | Corr: {best_score:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Accuracy and Metrics Report\n",
    "    # -----------------------------\n",
    "    print(\"\\n--- Detailed Accuracy Report ---\")\n",
    "    df = pd.DataFrame(results, columns=[\"Image\", \"True\", \"Predicted\", \"Correlation\"])\n",
    "    all_true = df[\"True\"].tolist()\n",
    "    all_pred = df[\"Predicted\"].tolist()\n",
    "\n",
    "    overall_acc = accuracy_score(all_true, all_pred)\n",
    "    overall_prec = precision_score(all_true, all_pred, average=\"macro\", zero_division=0)\n",
    "    overall_rec = recall_score(all_true, all_pred, average=\"macro\", zero_division=0)\n",
    "    overall_f1 = f1_score(all_true, all_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"\\nâœ… Overall Accuracy : {overall_acc*100:.2f}%\")\n",
    "    print(f\"âœ… Precision        : {overall_prec*100:.2f}%\")\n",
    "    print(f\"âœ… Recall           : {overall_rec*100:.2f}%\")\n",
    "    print(f\"âœ… F1-Score         : {overall_f1*100:.2f}%\\n\")\n",
    "\n",
    "    print(\"--- Per-Phone Metrics ---\")\n",
    "    for phone in phones:\n",
    "        preds = df[df[\"True\"] == phone][\"Predicted\"]\n",
    "        trues = df[df[\"True\"] == phone][\"True\"]\n",
    "        if len(trues) == 0:\n",
    "            continue\n",
    "        acc = np.mean(preds == trues)\n",
    "        print(f\"{phone:<25}: {acc*100:.2f}% ({len(trues)} queries)\")\n",
    "\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(all_true, all_pred, labels=phones)\n",
    "    cm_df = pd.DataFrame(cm, index=phones, columns=phones)\n",
    "    print(cm_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Run\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_sss_prnu_pipeline(DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
